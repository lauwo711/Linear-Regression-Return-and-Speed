{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels import regression\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.diagnostic as smd\n",
    "import statsmodels.stats.outliers_influence as smo\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, datasets\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ordinary Least Square Regression**<br>\n",
    "\n",
    "Assume residuals are independently, normally distributed with zero mean and unit variance.<br>\n",
    "\n",
    "In GLS, the following error term is minimized:\n",
    "\n",
    "$ (\\mathbf {y} -\\mathbf {X} \\mathbf {b} )^{\\mathtt {T}}\\,\\mathbf {\\Omega } ^{-1}(\\mathbf {y} -\\mathbf {X} \\mathbf {b}) $ , where $\\Omega $ is the covariance matrix of residuals. \n",
    "\n",
    "In OLS, $\\Omega $ = $I$, so the error term to be minimized is: <br>\n",
    "\n",
    "$ (\\mathbf {y} -\\mathbf {X} \\mathbf {b} )^{\\mathtt {T}}\\,\\mathbf (\\mathbf {y} -\\mathbf {X} \\mathbf {b}) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(X,Y):\n",
    "    # Running the linear regression\n",
    "    X = sm.add_constant(X)\n",
    "    model = regression.linear_model.OLS(Y, X).fit() #model the cov matrix of residual by OLS.fit(cov_type='HC1')\n",
    "    return model #or return model.get_robustcov_results(cov_type='HC1').summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regression plot and Residuls plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_resid_plot(model,X,Y,x_label,y_label):\n",
    "    f,ax = plt.subplots(1,2)\n",
    "    plt.figure(figsize=(50,50))\n",
    "    \n",
    "    a = model.params[0]\n",
    "    b = model.params[1]\n",
    "\n",
    "    # Return summary of the regression and plot results\n",
    "    X2 = np.linspace(X.min(), X.max(), 100)\n",
    "    Y_hat = X2 * b + a\n",
    "    ax[0].scatter(X, Y, alpha=0.3) # Plot the raw data\n",
    "    ax[0].plot(X2, Y_hat, 'r', alpha=0.9);  # Add the regression line, colored in red\n",
    "    plt.setp(ax[0], xlabel=x_label)\n",
    "    plt.setp(ax[0], ylabel=y_label)\n",
    "    ax[0].set_title('Regression')\n",
    "    \n",
    "    ax[1].scatter(model.predict(), model.resid, alpha=0.3);\n",
    "    ax[1].axhline(0, color='red')\n",
    "    plt.setp(ax[1], xlabel='Predicted_'+ y_label)\n",
    "    plt.setp(ax[1], ylabel=y_label)\n",
    "    ax[1].set_title('Residual plot')\n",
    "    \n",
    "    f.set_figheight(4)\n",
    "    f.set_figwidth(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_plot(model,X,Y,x_label,y_label):\n",
    "    a = model.params[0]\n",
    "    b = model.params[1]\n",
    "\n",
    "    # Return summary of the regression and plot results\n",
    "    X2 = np.linspace(X.min(), X.max(), 100)\n",
    "    Y_hat = X2 * b + a\n",
    "    plt.scatter(X, Y, alpha=0.3) # Plot the raw data\n",
    "    plt.plot(X2, Y_hat, 'r', alpha=0.9);  # Add the regression line, colored in red\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resid_plot(model,y_label):\n",
    "    plt.scatter(model.predict(), model.resid,alpha=0.3);\n",
    "    plt.axhline(0, color='red')\n",
    "    plt.xlabel('Predicted_'+ y_label);\n",
    "    plt.ylabel('Residuals');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weighted Least Square Regression**<br>\n",
    "\n",
    "Used when residuals are not correlated, but variance of residuals is not constant. <br>\n",
    "\n",
    "A weight is applied to each error term, the function to be minimized as follows:<br>\n",
    "\n",
    "$ \\sum _{i=1}^{m}w_{i}\\left|y_{i}-\\sum _{j=1}^{n}X_{ij}\\beta _{j}\\right|^{2} $ = $ (\\mathbf {y} -\\mathbf {X} \\mathbf {b} )^{\\mathtt {T}}\\,\\mathbf {W}^{-1}(\\mathbf {y} -\\mathbf {X} \\mathbf {b}) $ <br>\n",
    "\n",
    "where $W$ is a diagonal matrix (also the cov-var matrix of residuals) to be modelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wls_reg(X,Y):\n",
    "    X = sm.add_constant(X)\n",
    "    model = regression.linear_model.OLS(Y, X).fit()\n",
    "    model_1 = sm.WLS(Y,X, weights=1/(model.resid**2)).fit() #model the weight: higher error > lower weight\n",
    "    return model_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Robust Regression**<br>\n",
    "\n",
    "${W}$ can be modeled as a function of residuals, which is a function of $\\mathbf {X} ,\\mathbf {y}, \\mathbf {b}$ <br>\n",
    "${W}$ = $f (\\mathbf {X} ,\\mathbf {y}, \\mathbf {b})$<br>\n",
    "\n",
    "Also, regression coefficients ${b}$ is a function of $\\mathbf {X} ,\\mathbf {y}, \\mathbf {W}$<br>\n",
    "${b}$ = $g (\\mathbf {X} ,\\mathbf {y}, \\mathbf {W})$<br>\n",
    "\n",
    "In Robust Regression, iteration starts with ${W_{0}}$ = $I$ (indeed OLS), then ${W_{0}}$ is put back to $g$ and generate ${b_{o}}$, which is then put to $f$ to generate ${W_{1}}$.<br>\n",
    "The process is repeated until ${b}$ converges.<br>\n",
    "Please refer below for different models for the residual weight ${W}$.<br><br>\n",
    "https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/NCSS/Robust_Regression.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_reg(X,Y):\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.RLM(Y,X ,M=sm.robust.norms.HuberT()).fit() # select algo\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detect Heteroscedasticity (non costant variance of residuals)**<br>\n",
    "\n",
    "Heteroscedasticity violates one of the assumptions of OLS.\n",
    "\n",
    "Use breuschpagan test for graually increased residuals.<br>\n",
    "Use whtie test for graually increased residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bp_test(model):\n",
    "    pval = smd.het_breuschpagan(model.resid, model.model.exog)[1]\n",
    "    if pval<0.05:\n",
    "        print(\"BP test p-val: \",  pval,\". Using threshold 5%, the residual is heteroscedastic\")\n",
    "    else:\n",
    "        print(\"BP test p-val: \",  pval,\". Using threshold 5%, the residual is not heteroscedastic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def white_test(model):\n",
    "    pval = smd.het_white(model.resid, model.model.exog)[1]\n",
    "    if pval<0.05:\n",
    "        print(\"White test p-val: \",  pval,\". Using threshold 5%, the residual is heteroscedastic\")\n",
    "    else:\n",
    "        print(\"White test p-val: \",  pval,\". Using threshold 5%, the residual is not heteroscedastic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ransac(X,Y):\n",
    "    #x = np.array(data_set)[:,3:4]\n",
    "    #y = np.array(data_set)[:,0:1]\n",
    "\n",
    "    # Robustly fit linear model with RANSAC algorithm\n",
    "    ransac = linear_model.RANSACRegressor(residual_threshold=1.5) #larger threshold > less outlier\n",
    "    ransac.fit(X, Y)\n",
    "    inlier_mask = ransac.inlier_mask_\n",
    "    outlier_mask = np.logical_not(inlier_mask)\n",
    "\n",
    "    # Predict data of estimated models\n",
    "    line_X = np.arange(X.min(), X.max())[:, np.newaxis]\n",
    "    line_y_ransac = ransac.predict(line_X)\n",
    "\n",
    "    print(\"Estimated coefficients (true, linear regression, RANSAC):\")\n",
    "    print(ransac.estimator_.coef_, ransac.estimator_.intercept_)\n",
    "\n",
    "    plt.plot(line_X, line_y_ransac, color='cornflowerblue', linewidth=2,\n",
    "             label='RANSAC regressor')\n",
    "    plt.scatter(X[inlier_mask], Y[inlier_mask], color='yellowgreen', marker='.',\n",
    "                label='Inliers')\n",
    "    plt.scatter(X[outlier_mask], Y[outlier_mask], color='gold', marker='.',\n",
    "                label='Outliers')\n",
    "    plt.legend(loc='lower right')\n",
    "    \n",
    "    return ransac.estimator_.coef_, ransac.estimator_.intercept_, ransac.fit(X, Y).score(X, Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
